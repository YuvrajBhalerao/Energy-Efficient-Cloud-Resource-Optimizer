import os
import pandas as pd
from flask import Flask, render_template, jsonify

# --- Corrected Imports ---
# When running from the root, Python sees 'optimizer' as a top-level package.
from optimizer.data_loader import load_and_preprocess_data
from optimizer.feature_engineer import create_features
from optimizer.model import UsagePredictor
from optimizer.resource_allocator import allocate_resources
from optimizer.simulator import simulate_costs

# --- App Initialization ---
app = Flask(__name__)

# --- Dummy Data Generation ---
def create_dummy_data_if_not_exists():
    """Creates dummy CSV files if they don't already exist."""
    data_dir = 'data'
    metrics_path = os.path.join(data_dir, 'sample_metrics.csv')
    simulation_path = os.path.join(data_dir, 'sample_simulation.csv')

    if not os.path.exists(data_dir):
        os.makedirs(data_dir)

    if not os.path.exists(metrics_path):
        print("Creating dummy metrics data...")
        # Create a sample dataframe for metrics
        timestamps = pd.to_datetime(pd.date_range(start='2025-01-01', periods=100, freq='h'))
        data = {
            'timestamp': timestamps,
            'cpu_usage': [50 + i * 0.5 + 10 * (i % 6) for i in range(100)],
            'gpu_usage': [30 + i * 0.2 - 5 * (i % 8) for i in range(100)],
            'memory_usage': [60 - i * 0.3 + 15 * (i % 5) for i in range(100)]
        }
        df_metrics = pd.DataFrame(data)
        df_metrics.to_csv(metrics_path, index=False)
    
    # The simulation file is generated by the simulation logic, so we don't create it here.

# Run data creation at startup
create_dummy_data_if_not_exists()


# --- API Routes ---

@app.route('/')
def home():
    """Renders the main dashboard page."""
    return render_template('index.html')

@app.route('/api/run-optimization', methods=['POST'])
def run_optimization_endpoint():
    """
    Full pipeline: Load data, train model, predict, allocate, and simulate.
    """
    try:
        # 1. Load and prepare data
        metrics_path = 'data/sample_metrics.csv'
        df = load_and_preprocess_data(metrics_path)
        df = create_features(df)

        # 2. Train model and predict
        # In a real app, you might load a pre-trained model
        predictor = UsagePredictor()
        predictor.train(df, ['cpu_usage', 'gpu_usage', 'memory_usage'])
        predictions = predictor.predict(df)
        df['predicted_cpu'] = predictions[:, 0]
        df['predicted_gpu'] = predictions[:, 1]
        df['predicted_mem'] = predictions[:, 2]

        # 3. Allocate resources based on predictions
        df_allocations = allocate_resources(df, 'predicted_cpu', 'predicted_gpu', 'predicted_mem')

        # 4. Simulate costs
        simulation_results = simulate_costs(df_allocations)

        # 5. Prepare and return JSON response
        response_data = {
            "total_intervals": len(simulation_results),
            "original_cost": simulation_results['original_cost'].sum(),
            "optimized_cost": simulation_results['optimized_cost'].sum(),
            "cost_savings": simulation_results['cost_saved'].sum(),
            "cost_savings_percent": (simulation_results['cost_saved'].sum() / simulation_results['original_cost'].sum()) * 100,
            "energy_saved_kwh": simulation_results['energy_saved_kwh'].sum()
        }
        
        return jsonify({"status": "success", "data": response_data})

    except FileNotFoundError:
        return jsonify({"status": "error", "message": "Sample data file not found. Ensure 'data/sample_metrics.csv' exists."}), 500
    except Exception as e:
        app.logger.error(f"An error occurred during optimization: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

if __name__ == '__main__':
    # This block is for local development only
    # Gunicorn runs the app directly in production
    app.run(debug=True, port=5001)

